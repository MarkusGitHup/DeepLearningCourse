{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Solution-for-exercise:-Experiments-with-CNNs\" data-toc-modified-id=\"Solution-for-exercise:-Experiments-with-CNNs-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Solution for exercise: Experiments with CNNs</a></span></li><li><span><a href=\"#Are-all-libraries-that-are-needed-available?\" data-toc-modified-id=\"Are-all-libraries-that-are-needed-available?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Are all libraries that are needed available?</a></span></li><li><span><a href=\"#Class-for-providing-images\" data-toc-modified-id=\"Class-for-providing-images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Class for providing images</a></span></li><li><span><a href=\"#Function-for-building-a-CNN-(using-Keras)\" data-toc-modified-id=\"Function-for-building-a-CNN-(using-Keras)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Function for building a CNN (using Keras)</a></span></li><li><span><a href=\"#Function-for-training-a-CNN\" data-toc-modified-id=\"Function-for-training-a-CNN-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Function for training a CNN</a></span></li><li><span><a href=\"#Function-for-testing-a-CNN-model\" data-toc-modified-id=\"Function-for-testing-a-CNN-model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Function for testing a CNN model</a></span></li><li><span><a href=\"#Experiment:-Sensitivity-of-start-weights\" data-toc-modified-id=\"Experiment:-Sensitivity-of-start-weights-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Experiment: Sensitivity of start weights</a></span></li><li><span><a href=\"#Experiment:-Influence-of-training-dataset-size\" data-toc-modified-id=\"Experiment:-Influence-of-training-dataset-size-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Experiment: Influence of training dataset size</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution for exercise: Experiments with CNNs\n",
    "\n",
    "Prepare a folder data with the following structure:\n",
    "\n",
    "    data\n",
    "        train\n",
    "            car\n",
    "            bike\n",
    "        test\n",
    "            car\n",
    "            bike\n",
    "            \n",
    "and store at least some\n",
    "- hundreds-1000 of images for each object category in the training subfolders\n",
    "- some hundreds of images for each object category in the test subfolders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Are all libraries that are needed available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your NumPy version is:      1.16.2\n",
      "Your TensorFlow version is: 1.13.1\n",
      "Your Keras version is:      2.2.4\n",
      "Your OpenCV version is:     4.1.0\n",
      "Your Matplotlib version is: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print( \"Your NumPy version is:      \" + np.__version__ )\n",
    "print( \"Your TensorFlow version is: \" + tf.__version__)\n",
    "print( \"Your Keras version is:      \" + keras.__version__ )\n",
    "print( \"Your OpenCV version is:     \" + cv2.__version__ )\n",
    "print( \"Your Matplotlib version is: \" + matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for providing images\n",
    "\n",
    "We define a class ``image_provider`` that will give us a convenient access to the images.\n",
    "\n",
    "Given a root folder (e.g. \"C:\\\\data\"), it automatically determines which subfolders are there (e.g. \"C:\\\\data\\\\car\" and \"C:\\\\data\\\\bike\"). Each subfolder is assumed to be one of the categories we are interested in (e.g. \"car\" and \"bike\").\n",
    "\n",
    "An image provide object then stores a list of all training items:\n",
    "    \n",
    "        [filename1, class_id, class_name, teacher_vec]\n",
    "        [filename2, class_id, class_name, teacher_vec]\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile, join\n",
    "\n",
    "IMG_SIZE = (100,100)\n",
    "    \n",
    "class image_provider:\n",
    "    \n",
    "    #\n",
    "    # Traverses all subfolders of the specified root_folder\n",
    "    # and generates a list of the form:\n",
    "    #\n",
    "    # [ [\"data/bikes/jfksdj43.jpg\", \"bikes\",\n",
    "    #   [\"data/cars/bvcnm401.jpg\", \"cars\"],\n",
    "    #   ...\n",
    "    # ]\n",
    "    #\n",
    "    def __init__(self, root_folder,\n",
    "                 nr_imgs_per_class_to_use):\n",
    "        \n",
    "        # 1. The result of the image scan will be stored\n",
    "        #    in this list\n",
    "        self.all_training_items = []\n",
    "       \n",
    "    \n",
    "        # 2. Get a list of all subfolders =\n",
    "        #    a list of all image classes        \n",
    "        self.class_names = \\\n",
    "            [d for d in listdir(root_folder)\n",
    "             if isdir(os.path.join(root_folder,d))]\n",
    "        \n",
    "        #print(\"Under folder\\n\\t\", root_folder,\n",
    "        #      \"\\nI found the following subfolders/classes:\")\n",
    "        #print(self.class_names)\n",
    "    \n",
    "    \n",
    "        # 3. How many classes are there?\n",
    "        self.nr_classes = len(self.class_names)\n",
    "    \n",
    "    \n",
    "        # 4. For each subfolder ...\n",
    "        total_nr_imgs_in_principle_available = 0\n",
    "        for class_id, class_name in enumerate(self.class_names):\n",
    "            \n",
    "            # 4.1 Compute absolute folder name\n",
    "            subfolder_name = root_folder + \"/\" + class_name + \"/\"\n",
    "            \n",
    "            # 4.2 Get list of image files in that class image folder\n",
    "            filenames = \\\n",
    "                [subfolder_name + f\n",
    "                 for f in listdir(subfolder_name)\n",
    "                 if isfile(join(subfolder_name, f))]\n",
    "            \n",
    "            #print(\"{} files in subfolder {}\".format(len(filenames),\n",
    "            #                                        subfolder_name) )\n",
    "            \n",
    "            # 4.3 How many images to get from that folder?\n",
    "            nr_files_available = len(filenames)\n",
    "            total_nr_imgs_in_principle_available += nr_files_available\n",
    "            nr_files_to_store = min(nr_files_available,\n",
    "                                    nr_imgs_per_class_to_use)\n",
    "            \n",
    "            # 4.4 For each image filename in current subfolder ...\n",
    "            for file_nr in range(0,nr_files_to_store):\n",
    "                \n",
    "                # get next filename\n",
    "                filename = filenames[file_nr]\n",
    "                \n",
    "                # prepare a one-hot encoded class teacher vector\n",
    "                teacher_vec = np.zeros( self.nr_classes )\n",
    "                teacher_vec[class_id] = 1.0\n",
    "                \n",
    "                # store \"training item\" which is mainly\n",
    "                # the information of the image filename\n",
    "                self.all_training_items.append(\n",
    "                    [filename, class_id, class_name, teacher_vec] )              \n",
    "        \n",
    "        \n",
    "        # 5. Show how many images are in principle available\n",
    "        #    and how many we \"extracted\" \n",
    "        self.nr_images = len(self.all_training_items)\n",
    "        print(\"There are {} images in total available.\"\n",
    "              .format(total_nr_imgs_in_principle_available))\n",
    "        print(\"Since I only should extract {} images \"\n",
    "              \"per class, I stored in total (only) {} image files.\"\n",
    "              .format(nr_imgs_per_class_to_use, self.nr_images))        \n",
    "        \n",
    "        #print(\"Here are the first 3 entries of the training items list generated:\")\n",
    "        #print(self.all_training_items[:3])\n",
    "        \n",
    "    \n",
    "    \n",
    "    #   \n",
    "    # Given an absolute filename,\n",
    "    # load the image in using OpenCV,\n",
    "    # then convert it to usual RGB color channel order\n",
    "    # and scale values to be in range [0,1]\n",
    "    #\n",
    "    def load_image(self, absolute_filename):\n",
    "        \n",
    "        image = cv2.imread(absolute_filename)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "        image = cv2.resize(image, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        image = image * (1.0 / 255.0)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "        \n",
    "       \n",
    "    #\n",
    "    # Return the image from the dataset\n",
    "    # with the specified index\n",
    "    #\n",
    "    def get_specific_image(self, idx):\n",
    "        \n",
    "        image_filename  = self.all_training_items[idx][0]\n",
    "        class_id        = self.all_training_items[idx][1]\n",
    "        class_name      = self.all_training_items[idx][2]\n",
    "        teacher_vec     = self.all_training_items[idx][3]\n",
    "        \n",
    "        image = self.load_image(image_filename)\n",
    "        \n",
    "        return image, class_id, class_name, teacher_vec\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # Return an OpenCV image and the class label\n",
    "    # where the image is chosen randomly from the\n",
    "    # list of all images.\n",
    "    #\n",
    "    def get_random_image(self):\n",
    "        \n",
    "        rnd_idx = np.random.randint(0, self.nr_images)\n",
    "        #print(\"Returning random image with index\", rnd_idx)\n",
    "        return self.get_specific_image( rnd_idx )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the image provider class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 images in total available.\n",
      "Since I only should extract 10 images per class, I stored in total (only) 20 image files.\n"
     ]
    }
   ],
   "source": [
    "train_folder = \"V:\\\\01_job\\\\12_datasets\\\\01_imagenet_cars_vs_bikes\\\\train\"\n",
    "nr_images_to_retrieve_per_class = 10\n",
    "train_img_provider = image_provider( train_folder,\n",
    "                                     nr_images_to_retrieve_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us retrieve randomly one of the images and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image has type <class 'numpy.ndarray'>\n",
      "image has shape (100, 100, 3)\n",
      "teacher vec: [1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJZQNKv8/GGiBxNTlO10AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290478a6a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, class_id, class_name, teacher_vec = \\\n",
    "    train_img_provider.get_random_image()\n",
    "    \n",
    "THE_INPUT_IMG_SHAPE = image.shape\n",
    "    \n",
    "print(\"image has type\", type(image))\n",
    "print(\"image has shape\", image.shape)\n",
    "print(\"teacher vec:\", teacher_vec)\n",
    "plt.imshow(image)\n",
    "plt.title(\"One of the images with label {}\".format(class_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for building a CNN (using Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "def build_cnn_model(input_shape_of_single_image, nr_output_neurons):\n",
    "    \n",
    "    \n",
    "    # clear the last Keras session\n",
    "    # this will clear the underlying TensorFlow graph\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1. Define the feature hierarchy:\n",
    "    \n",
    "    # Layer 1\n",
    "    nr_filter       = 32\n",
    "    kernel_side_len = 4\n",
    "    kernel_stride   = 2\n",
    "    model.add(Conv2D(nr_filter,\n",
    "                     kernel_size=(kernel_side_len, kernel_side_len),\n",
    "                     strides=(kernel_stride, kernel_stride),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape_of_single_image)\n",
    "             )\n",
    "    \n",
    "    # Layer 2\n",
    "    kernel_side_len = 2\n",
    "    kernel_stride   = 2\n",
    "    model.add(MaxPooling2D(pool_size=(kernel_side_len, kernel_side_len),\n",
    "                           strides=(kernel_stride, kernel_stride))\n",
    "             )\n",
    "\n",
    "    # 2. Define the MLP part:\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nr_output_neurons, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # 3. Show the model\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    # 4. Build model and configure model for training\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "# end build_a_cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for training a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_cnn(your_cnn, train_img_provider, nr_train_steps):\n",
    "    \n",
    "    train_time_start = time.time()\n",
    "    \n",
    "    height      = THE_INPUT_IMG_SHAPE[0]\n",
    "    width       = THE_INPUT_IMG_SHAPE[1]\n",
    "    nr_channels = THE_INPUT_IMG_SHAPE[2]\n",
    "\n",
    "    X = np.zeros( (1,height,width,nr_channels)     )\n",
    "    Y = np.zeros( (1,train_img_provider.nr_classes) )\n",
    "\n",
    "    print(\"Steps to train: {}\".format(nr_train_steps))\n",
    "    \n",
    "    for train_step in range(0,nr_train_steps):\n",
    "\n",
    "        if train_step % 500 == 0:\n",
    "            print(\"training step \", train_step)\n",
    "\n",
    "        # 1. get the next random image from the dataset\n",
    "        image, class_id, class_name, teacher_vec = \\\n",
    "            train_img_provider.get_random_image()\n",
    "\n",
    "        # 2. put the image into a 4D array\n",
    "        #    note: Keras expects a 4D array as input for\n",
    "        #          the training function fit()\n",
    "        X[0,:,:,:] = image\n",
    "\n",
    "        # 3. the teacher value array expected by Keras\n",
    "        #    is a 2D array\n",
    "        Y[0,:] = teacher_vec\n",
    "\n",
    "\n",
    "        # 3. train the model using this image    \n",
    "        my_cnn.fit(X,Y,verbose=0)        \n",
    "    \n",
    "    train_time_end = time.time()\n",
    "    print(\"Training finished!\")    \n",
    "            \n",
    "    train_duration_sec = train_time_end - train_time_start\n",
    "    print(\"Training time: {:.2f} sec = {:.2f} min\"\n",
    "          .format(train_duration_sec,\n",
    "                  train_duration_sec/60)\n",
    "          )\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for testing a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_cnn(your_cnn,\n",
    "             test_img_provider,\n",
    "             show_example_predictions):\n",
    "    \n",
    "    nr_test_images = test_img_provider.nr_images\n",
    "    \n",
    "    correct_classified = 0\n",
    "    \n",
    "    print(\"I will test the CNN on {} test images\".\n",
    "          format(nr_test_images))\n",
    "    \n",
    "    for test_img_nr in range(0, nr_test_images):\n",
    "        \n",
    "        if test_img_nr % 100 == 0:\n",
    "            print(\"Tested {} images so far\".\n",
    "                  format(test_img_nr))\n",
    "        \n",
    "        # 1. \n",
    "        # get the next test image from the\n",
    "        # test image provider\n",
    "        img, gt_class_nr, class_label, teacher_vec = \\\n",
    "            test_img_provider.get_specific_image( test_img_nr )\n",
    "    \n",
    "        \n",
    "        # 2.\n",
    "        # reshape image (3D array) to a 4D array\n",
    "        # since Keras wants 4D arrays as input\n",
    "        X = img.reshape((-1,\n",
    "                         img.shape[0],\n",
    "                         img.shape[1],\n",
    "                         img.shape[2]\n",
    "                        )\n",
    "                       )\n",
    "        \n",
    "        # 3.\n",
    "        # let the CNN predict the image class\n",
    "        neuron_outputs = your_cnn.predict(X)\n",
    "        \n",
    "        # 4.\n",
    "        # determine the predicted class nr\n",
    "        predicted_class_nr = np.argmax(neuron_outputs.reshape(-1))\n",
    "        \n",
    "        # 5.\n",
    "        # Did the CNN correctly predict the class?\n",
    "        if predicted_class_nr == gt_class_nr:\n",
    "            correct_classified +=1\n",
    "        prediced_class_label = \\\n",
    "            test_img_provider.class_names[predicted_class_nr]\n",
    "            \n",
    "        # 6.\n",
    "        # Show image, predicted class and gt class?\n",
    "        if show_example_predictions and np.random.randint(50)==0:\n",
    "                        \n",
    "            plt.title(\"Is: {} vs. Predicted: {}\\nNeuron out: {}\"\n",
    "                      .format(class_label,\n",
    "                              prediced_class_label,\n",
    "                              neuron_outputs\n",
    "                             )\n",
    "                     )\n",
    "            plt.imshow( img )\n",
    "            plt.show()\n",
    "            \n",
    "        \n",
    "    # finally, compute the correct classification rate\n",
    "    corr_classification_rate = \\\n",
    "        float(correct_classified) / float(nr_test_images)\n",
    "        \n",
    "    print(\"Correctly classified: {} of {} images:\"\n",
    "          \" --> rate: {:.2f}\"\n",
    "          .format(correct_classified,\n",
    "                  nr_test_images,\n",
    "                  corr_classification_rate)\n",
    "         )   \n",
    "    \n",
    "    # return the correct classification rate\n",
    "    return corr_classification_rate\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Sensitivity of start weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 images in total available.\n",
      "Since I only should extract 10000 images per class, I stored in total (only) 2000 image files.\n",
      "There are 651 images in total available.\n",
      "Since I only should extract 10000 images per class, I stored in total (only) 651 image files.\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 0\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 51.15 sec = 0.85 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 469 of 651 images: --> rate: 0.72\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 1\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 6.1854742e-02 -5.7669606e-02  8.5171409e-02]\n",
      "  [ 6.1782077e-03  5.9433408e-02 -4.1681975e-02]\n",
      "  [-5.4724675e-02 -3.0028656e-02 -3.5315752e-05]\n",
      "  [ 4.4157021e-02  5.9531800e-02  9.6610792e-02]]\n",
      "\n",
      " [[ 1.0349616e-01  9.5900811e-02  2.9043861e-02]\n",
      "  [-1.6740263e-03  5.5609770e-02  3.3339061e-02]\n",
      "  [ 2.2314556e-02 -9.1733716e-02 -2.7765699e-02]\n",
      "  [-3.2811448e-02 -3.3906788e-02 -1.9081570e-02]]\n",
      "\n",
      " [[-4.0750086e-02  3.8949825e-02  8.4119342e-02]\n",
      "  [ 3.9157070e-02  2.3163773e-02  4.6656452e-02]\n",
      "  [-5.6188293e-02  8.9421101e-02 -1.0171348e-01]\n",
      "  [ 6.2403008e-03  5.9120208e-03  1.7050371e-02]]\n",
      "\n",
      " [[-6.6320986e-02  6.9913708e-02  1.1101671e-02]\n",
      "  [-2.9850602e-02  6.5310098e-02 -8.1746191e-02]\n",
      "  [ 2.6246749e-02  9.3549274e-02 -3.4128651e-03]\n",
      "  [ 4.6345867e-02  4.8017316e-02 -5.6361414e-02]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.88 sec = 0.83 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 544 of 651 images: --> rate: 0.84\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 2\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.05825908  0.05977494 -0.03064481]\n",
      "  [ 0.08037285  0.08916602 -0.08449361]\n",
      "  [ 0.013506   -0.05745216  0.06143182]\n",
      "  [ 0.03450079 -0.00529501  0.02331836]]\n",
      "\n",
      " [[-0.10311187 -0.07127054  0.1000799 ]\n",
      "  [-0.10271627  0.08488766 -0.05831547]\n",
      "  [ 0.09595335  0.07482465  0.09321717]\n",
      "  [ 0.01645596 -0.0557769  -0.02186079]]\n",
      "\n",
      " [[ 0.0909422  -0.03979208  0.01603953]\n",
      "  [-0.00837811  0.04122413 -0.04014284]\n",
      "  [-0.05154781  0.08006444 -0.09809985]\n",
      "  [ 0.03081959  0.07000267  0.06598528]]\n",
      "\n",
      " [[-0.03899353 -0.08910029  0.05901442]\n",
      "  [-0.01001471 -0.05753743 -0.05193986]\n",
      "  [-0.01949546  0.0758624  -0.09248561]\n",
      "  [ 0.0645765   0.00664342  0.065179  ]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.38 sec = 0.82 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 530 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 3\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.03342289 -0.08622016  0.04941326]\n",
      "  [ 0.05662917  0.05373245 -0.02440436]\n",
      "  [ 0.08903389  0.06935053 -0.03656396]\n",
      "  [-0.04864775 -0.03233019  0.09529433]]\n",
      "\n",
      " [[-0.0762443   0.00909996 -0.0444026 ]\n",
      "  [ 0.00881998 -0.03537897 -0.05110468]\n",
      "  [-0.03755493  0.02339148  0.06183884]\n",
      "  [ 0.00125523 -0.07566102  0.00775285]]\n",
      "\n",
      " [[ 0.00323799  0.02732841 -0.04353068]\n",
      "  [ 0.07331225  0.07937758 -0.0294089 ]\n",
      "  [ 0.06077727  0.07114924  0.08409738]\n",
      "  [-0.03550315  0.07569233  0.00471745]]\n",
      "\n",
      " [[-0.10030746 -0.00074488 -0.05525995]\n",
      "  [-0.0376347  -0.09602566 -0.06929859]\n",
      "  [ 0.06489786  0.05627491  0.07218405]\n",
      "  [ 0.07919974  0.00285638  0.08261917]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 48.75 sec = 0.81 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 544 of 651 images: --> rate: 0.84\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 4\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.09409692  0.02604606  0.0107428 ]\n",
      "  [-0.09465217  0.07397478 -0.07046801]\n",
      "  [ 0.01907126  0.04506325  0.04390829]\n",
      "  [-0.03513616 -0.08696133  0.04868286]]\n",
      "\n",
      " [[-0.02331786  0.0737187  -0.0620247 ]\n",
      "  [ 0.0099419  -0.07077928  0.0011117 ]\n",
      "  [-0.01206587  0.01259841  0.03193269]\n",
      "  [ 0.07782618  0.02835784  0.03830025]]\n",
      "\n",
      " [[-0.04343527  0.00886601  0.0515415 ]\n",
      "  [ 0.03197575  0.07556652  0.03677442]\n",
      "  [ 0.06659516  0.04018363  0.01208436]\n",
      "  [ 0.03951106 -0.04433348  0.0088395 ]]\n",
      "\n",
      " [[ 0.07233169 -0.05293463 -0.09855656]\n",
      "  [-0.07639582 -0.06391047  0.1011352 ]\n",
      "  [ 0.09421524  0.01302871  0.02135906]\n",
      "  [-0.07763147 -0.00216294 -0.03874067]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.27 sec = 0.82 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 490 of 651 images: --> rate: 0.75\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 5\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[-0.07076791  0.08021962 -0.06087181]\n",
      "  [ 0.00599896  0.05223908  0.09313502]\n",
      "  [ 0.01338223 -0.01685995 -0.04182679]\n",
      "  [ 0.08771736 -0.01696829  0.08331019]]\n",
      "\n",
      " [[-0.08076692 -0.03499062 -0.03393934]\n",
      "  [-0.02997715  0.05779066 -0.01025845]\n",
      "  [-0.04980491  0.01870488 -0.00674888]\n",
      "  [ 0.07326601  0.01620229 -0.01984493]]\n",
      "\n",
      " [[-0.08817111  0.02234804 -0.03539405]\n",
      "  [-0.04026715 -0.00905801 -0.02240633]\n",
      "  [ 0.01555822 -0.09825847  0.06612866]\n",
      "  [ 0.07952518  0.09365537  0.03720028]]\n",
      "\n",
      " [[ 0.06745584 -0.01119427  0.01450222]\n",
      "  [-0.04242707  0.06222767 -0.02218464]\n",
      "  [ 0.0360909   0.03286039  0.02219933]\n",
      "  [ 0.02226078  0.01675829 -0.05780395]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 48.51 sec = 0.81 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 527 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 6\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.04639543  0.05324336  0.02340695]\n",
      "  [ 0.08019545  0.01599565  0.06106243]\n",
      "  [ 0.05966581  0.00032216  0.05396398]\n",
      "  [-0.03208121 -0.01569973 -0.02035642]]\n",
      "\n",
      " [[ 0.075731    0.09027614  0.01196992]\n",
      "  [-0.10157066 -0.0530792   0.07603375]\n",
      "  [ 0.03603715  0.02236413 -0.08966503]\n",
      "  [-0.04495873 -0.0586164  -0.0116736 ]]\n",
      "\n",
      " [[ 0.09878599 -0.07534373  0.0558074 ]\n",
      "  [ 0.06831337 -0.06346378 -0.00514479]\n",
      "  [ 0.02811789  0.06749626  0.01080963]\n",
      "  [ 0.02889245 -0.00720005  0.03633215]]\n",
      "\n",
      " [[-0.0135667  -0.02998713  0.04200529]\n",
      "  [ 0.04388418  0.05202211 -0.064546  ]\n",
      "  [ 0.09770542  0.07147614  0.0883707 ]\n",
      "  [ 0.06260418 -0.04506164  0.00607838]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 47.70 sec = 0.80 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 542 of 651 images: --> rate: 0.83\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 7\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.03717858 -0.00830057 -0.03820322]\n",
      "  [ 0.04328283 -0.07296922 -0.03903541]\n",
      "  [-0.07705949  0.02932041  0.01846317]\n",
      "  [-0.07401436 -0.04822054 -0.06611864]]\n",
      "\n",
      " [[-0.02519144 -0.08875222  0.06140556]\n",
      "  [ 0.05234452 -0.05367003 -0.0769184 ]\n",
      "  [-0.00537926  0.08771003 -0.02504784]\n",
      "  [ 0.04775391 -0.0524492  -0.04005252]]\n",
      "\n",
      " [[ 0.00819036 -0.05502585 -0.03676724]\n",
      "  [-0.00654817  0.05659806 -0.06775501]\n",
      "  [-0.1012582   0.06954298  0.04741784]\n",
      "  [ 0.00577994  0.08063497 -0.02401089]]\n",
      "\n",
      " [[-0.08519121 -0.08853043  0.07927891]\n",
      "  [ 0.09761459  0.05890857 -0.0267192 ]\n",
      "  [-0.07444989 -0.00416971 -0.10250295]\n",
      "  [ 0.05705678  0.09537841  0.05541144]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 46.94 sec = 0.78 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 532 of 651 images: --> rate: 0.82\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 8\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.07228527  0.06333775 -0.08255688]\n",
      "  [-0.0602602   0.05341362 -0.0611456 ]\n",
      "  [ 0.08817095 -0.09952009 -0.02438455]\n",
      "  [-0.0587259  -0.08549685 -0.02218255]]\n",
      "\n",
      " [[ 0.05161308 -0.02321196  0.06683924]\n",
      "  [ 0.0076956   0.09852459  0.04517729]\n",
      "  [-0.09175442 -0.03472012  0.00399153]\n",
      "  [ 0.01993903  0.01506497  0.03366872]]\n",
      "\n",
      " [[-0.07003078 -0.02324854  0.02702359]\n",
      "  [ 0.01757634  0.05020567 -0.01314492]\n",
      "  [ 0.07949976  0.03496969  0.07163186]\n",
      "  [-0.09148116  0.06522235 -0.01942919]]\n",
      "\n",
      " [[-0.09846097  0.08756066 -0.0749542 ]\n",
      "  [-0.08954     0.00471792 -0.06910047]\n",
      "  [-0.05280006 -0.02972881  0.06318576]\n",
      "  [ 0.06282756  0.01144177 -0.08453238]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 48.67 sec = 0.81 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 538 of 651 images: --> rate: 0.83\n",
      "\n",
      "\n",
      "\n",
      "**************\n",
      "Model nr: 9\n",
      "**************\n",
      "\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[-0.04973978 -0.05187663  0.02698734]\n",
      "  [-0.09437717  0.09243847  0.02767611]\n",
      "  [ 0.06471487 -0.09534961  0.05038463]\n",
      "  [ 0.08978578 -0.0971406   0.09760549]]\n",
      "\n",
      " [[ 0.10302805  0.0436885   0.01699568]\n",
      "  [ 0.06642026 -0.06520176 -0.01435277]\n",
      "  [ 0.05159292  0.01114802 -0.04230997]\n",
      "  [-0.07346909  0.016758    0.07790204]]\n",
      "\n",
      " [[ 0.03664545  0.02574366 -0.07935845]\n",
      "  [-0.01769016 -0.02366188 -0.01052856]\n",
      "  [-0.0945175  -0.01349067  0.09667658]\n",
      "  [ 0.05607594  0.05291957  0.04520609]]\n",
      "\n",
      " [[ 0.01573025  0.0943852  -0.08556746]\n",
      "  [ 0.0231074  -0.06829014  0.08258144]\n",
      "  [ 0.05340535  0.04506227  0.03029297]\n",
      "  [ 0.05465987 -0.01849454 -0.01259281]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 48.83 sec = 0.81 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 534 of 651 images: --> rate: 0.82\n"
     ]
    }
   ],
   "source": [
    "NR_MODELS_TO_TEST = 10\n",
    "\n",
    "# 1. prepare a train image provider\n",
    "train_folder = \"V:\\\\01_job\\\\12_datasets\\\\01_imagenet_cars_vs_bikes\\\\train\"\n",
    "nr_images_to_retrieve_per_class = 10000\n",
    "train_img_provider = image_provider( train_folder,\n",
    "                                     nr_images_to_retrieve_per_class)\n",
    "\n",
    "# 2. prepare a test image provider\n",
    "test_folder = \"V:\\\\01_job\\\\12_datasets\\\\01_imagenet_cars_vs_bikes\\\\test\"\n",
    "test_img_provider = image_provider( test_folder,\n",
    "                                    nr_images_to_retrieve_per_class)\n",
    "\n",
    "# 3. for all CNN models to generate...\n",
    "model_ids = []\n",
    "classification_rates = []\n",
    "for model_nr in range(0,NR_MODELS_TO_TEST):\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(\"**************\")\n",
    "    print(\"Model nr:\", model_nr)\n",
    "    print(\"**************\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # 3.1 create a new CNN model\n",
    "    \n",
    "    # Always start pseudo random number generator\n",
    "    # with same seed in order to start CNN with\n",
    "    # the same weights\n",
    "    # np.random.seed( 0 )\n",
    "    \n",
    "    # Always start pseudo random number generator\n",
    "    # with DIFFERENT seed in order to start CNN with\n",
    "    # the DIFFERENT weights\n",
    "    np.random.seed( model_nr )\n",
    "    \n",
    "    my_cnn = build_cnn_model(THE_INPUT_IMG_SHAPE,\n",
    "                             train_img_provider.nr_classes)\n",
    "    \n",
    "    print(\"Here are the filter weights of the \"\n",
    "          \"first conv filter in layer 0:\")\n",
    "    filter_weights_layer0 = my_cnn.layers[0].get_weights()[0]\n",
    "    filter0_weights = filter_weights_layer0[:,:,:,0]\n",
    "    print( filter0_weights.shape )\n",
    "    print( filter0_weights )\n",
    "\n",
    "    # 3.2 train the CNN model\n",
    "    train_cnn(my_cnn, train_img_provider, 5000)\n",
    "\n",
    "    # 3.3 test the model\n",
    "    show_example_predictions = False\n",
    "    corr_class_rate = test_cnn(my_cnn,\n",
    "                               test_img_provider,\n",
    "                               show_example_predictions)\n",
    "    \n",
    "    # 3.4 store classification rate\n",
    "    model_ids.append( model_nr )\n",
    "    classification_rates.append( corr_class_rate )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290444e3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum rate: 0.7204301075268817\n",
      "Maximum rate: 0.8356374807987711\n",
      "Range in percent: 11.520737327188934\n",
      "\n",
      " [0.7204301075268817, 0.8356374807987711, 0.8141321044546851, 0.8356374807987711, 0.7526881720430108, 0.8095238095238095, 0.8325652841781874, 0.8172043010752689, 0.82642089093702, 0.8202764976958525]\n"
     ]
    }
   ],
   "source": [
    "# Show comparison of different models as bar diagram\n",
    "plt.xticks(model_ids)\n",
    "plt.bar(model_ids, classification_rates)\n",
    "plt.title(\"Comparison of classification rates\")\n",
    "plt.xlabel(\"Model nr\")\n",
    "plt.ylabel(\"Correct classifcation rate\")\n",
    "plt.show()\n",
    "\n",
    "min_rate = min(classification_rates)\n",
    "max_rate = max(classification_rates)\n",
    "\n",
    "print(\"Minimum rate:\", min_rate)\n",
    "print(\"Maximum rate:\", max_rate)\n",
    "print(\"Range in percent:\", (max_rate-min_rate)*100.0)\n",
    "\n",
    "print(\"\\n\",classification_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion: The random start initialization has a large impact on the final correct classification rate of a CNN - when the number of training steps is fixed.**\n",
    "\n",
    "E.g. if you have luck you start with random weights that give you a correct classification rate of 83% after training N steps. However, if you have bad luck you can get with the same CNN and the same number of training steps a classification rate of only 72%, i.e. a 11% smaller correct classification rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Influence of training dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 651 images in total available.\n",
      "Since I only should extract 10000 images per class, I stored in total (only) 651 image files.\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 50\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 50 images per class, I stored in total (only) 100 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 57.66 sec = 0.96 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 488 of 651 images: --> rate: 0.75\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 100\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 100 images per class, I stored in total (only) 200 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 54.81 sec = 0.91 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 518 of 651 images: --> rate: 0.80\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 150\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 150 images per class, I stored in total (only) 300 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 53.26 sec = 0.89 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 526 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 200\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 200 images per class, I stored in total (only) 400 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 51.94 sec = 0.87 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 520 of 651 images: --> rate: 0.80\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 250\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 250 images per class, I stored in total (only) 500 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 52.68 sec = 0.88 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 529 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 300\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 300 images per class, I stored in total (only) 600 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 53.00 sec = 0.88 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 525 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 350\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 350 images per class, I stored in total (only) 700 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 50.50 sec = 0.84 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 541 of 651 images: --> rate: 0.83\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 400\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 400 images per class, I stored in total (only) 800 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 51.11 sec = 0.85 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 498 of 651 images: --> rate: 0.76\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 450\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 450 images per class, I stored in total (only) 900 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 50.55 sec = 0.84 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 525 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 500\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 500 images per class, I stored in total (only) 1000 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 50.21 sec = 0.84 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 504 of 651 images: --> rate: 0.77\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 550\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 550 images per class, I stored in total (only) 1100 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 50.72 sec = 0.85 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 540 of 651 images: --> rate: 0.83\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 600\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 600 images per class, I stored in total (only) 1200 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.85 sec = 0.83 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 538 of 651 images: --> rate: 0.83\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 650\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 650 images per class, I stored in total (only) 1300 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 50.34 sec = 0.84 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 535 of 651 images: --> rate: 0.82\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 700\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 700 images per class, I stored in total (only) 1400 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.92 sec = 0.83 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 535 of 651 images: --> rate: 0.82\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 750\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 750 images per class, I stored in total (only) 1500 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.33 sec = 0.82 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 532 of 651 images: --> rate: 0.82\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 800\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 800 images per class, I stored in total (only) 1600 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 48.90 sec = 0.82 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 529 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 850\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 850 images per class, I stored in total (only) 1700 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.37 sec = 0.82 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 534 of 651 images: --> rate: 0.82\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 900\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 900 images per class, I stored in total (only) 1800 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.43 sec = 0.82 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 526 of 651 images: --> rate: 0.81\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 950\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 950 images per class, I stored in total (only) 1900 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n",
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.59 sec = 0.83 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 543 of 651 images: --> rate: 0.83\n",
      "\n",
      "\n",
      "\n",
      "*************************************\n",
      "Nr of train images per class: 1000\n",
      "*************************************\n",
      "\n",
      "\n",
      "There are 2000 images in total available.\n",
      "Since I only should extract 1000 images per class, I stored in total (only) 2000 image files.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 32)        1568      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 36866     \n",
      "=================================================================\n",
      "Total params: 38,434\n",
      "Trainable params: 38,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Here are the filter weights of the first conv filter in layer 0:\n",
      "(4, 4, 3)\n",
      "[[[ 0.01025016  0.00282225  0.09363272]\n",
      "  [-0.04033086  0.04231644  0.06404627]\n",
      "  [ 0.01354985  0.03814205  0.0384951 ]\n",
      "  [ 0.0100013   0.08652072 -0.01655453]]\n",
      "\n",
      " [[-0.05521043  0.0807815   0.0900469 ]\n",
      "  [ 0.03752889  0.02315027 -0.09224059]\n",
      "  [-0.09453825 -0.0522247  -0.04932562]\n",
      "  [-0.10021615  0.07409681  0.10211349]]\n",
      "\n",
      " [[ 0.01281475  0.03586181  0.10193502]\n",
      "  [ 0.08621532 -0.09965098 -0.06756459]\n",
      "  [-0.03340623  0.05749614  0.06385877]\n",
      "  [-0.10113237  0.10074928 -0.05481243]]\n",
      "\n",
      " [[ 0.01542698 -0.0568672  -0.00554956]\n",
      "  [ 0.03499471 -0.0088127  -0.07950282]\n",
      "  [-0.01722468  0.07247847 -0.02570103]\n",
      "  [ 0.06072653  0.05828502  0.03766365]]]\n",
      "Steps to train: 5000\n",
      "training step  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step  500\n",
      "training step  1000\n",
      "training step  1500\n",
      "training step  2000\n",
      "training step  2500\n",
      "training step  3000\n",
      "training step  3500\n",
      "training step  4000\n",
      "training step  4500\n",
      "Training finished!\n",
      "Training time: 49.58 sec = 0.83 min\n",
      "I will test the CNN on 651 test images\n",
      "Tested 0 images so far\n",
      "Tested 100 images so far\n",
      "Tested 200 images so far\n",
      "Tested 300 images so far\n",
      "Tested 400 images so far\n",
      "Tested 500 images so far\n",
      "Tested 600 images so far\n",
      "Correctly classified: 492 of 651 images: --> rate: 0.76\n"
     ]
    }
   ],
   "source": [
    "# 1. prepare a test image provider\n",
    "test_folder = \"V:\\\\01_job\\\\12_datasets\\\\01_imagenet_cars_vs_bikes\\\\test\"\n",
    "test_img_provider = image_provider( test_folder,\n",
    "                                    nr_images_to_retrieve_per_class)\n",
    "\n",
    "# 2. for all CNN models to generate...\n",
    "train_dataset_sizes = []\n",
    "classification_rates = []\n",
    "STEP_SIZE = 50\n",
    "for nr_train_imgs_per_class in range(STEP_SIZE,1001,STEP_SIZE):\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*************************************\")\n",
    "    print(\"Nr of train images per class:\", nr_train_imgs_per_class)\n",
    "    print(\"*************************************\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # 2.1 prepare a train image provider\n",
    "    #     that uses the specified number of train\n",
    "    #     images per class\n",
    "    train_folder = \"V:\\\\01_job\\\\12_datasets\\\\01_imagenet_cars_vs_bikes\\\\train\"    \n",
    "    train_img_provider = image_provider( train_folder,\n",
    "                                         nr_train_imgs_per_class)\n",
    "\n",
    "\n",
    "    # 2.2 create a new CNN model\n",
    "    #     BUT (IMPORTANT!) ALWAYS\n",
    "    #     START WITH THE SAME WEIGHTS\n",
    "    #     IN ORDER TO MAKE THE INFLUENCE\n",
    "    #     OF THE DATASET SIZE COMPARABLE\n",
    "    #     else:\n",
    "    #     the random start initialization\n",
    "    #     of the weights have a too strong\n",
    "    #     influence onto the final classification\n",
    "    #     rate!\n",
    "    np.random.seed(0)\n",
    "    my_cnn = build_cnn_model(THE_INPUT_IMG_SHAPE,\n",
    "                             train_img_provider.nr_classes)\n",
    "    print(\"Here are the filter weights of the \"\n",
    "          \"first conv filter in layer 0:\")\n",
    "    filter_weights_layer0 = my_cnn.layers[0].get_weights()[0]\n",
    "    filter0_weights = filter_weights_layer0[:,:,:,0]\n",
    "    print( filter0_weights.shape )\n",
    "    print( filter0_weights )\n",
    "\n",
    "    # 2.3 train the CNN model\n",
    "    train_cnn(my_cnn, train_img_provider, 5000)\n",
    "\n",
    "    # 2.4 test the model\n",
    "    show_example_predictions = False\n",
    "    corr_class_rate = test_cnn(my_cnn,\n",
    "                               test_img_provider,\n",
    "                               show_example_predictions)\n",
    "    \n",
    "    # 2.5 store classification rate\n",
    "    train_dataset_sizes.append( nr_train_imgs_per_class )\n",
    "    classification_rates.append( corr_class_rate )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHzwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x290460ec978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum rate: 0.7496159754224271\n",
      "Maximum rate: 0.8341013824884793\n",
      "Range in percent: 8.448540706605224\n",
      "20\n",
      "[50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]\n",
      "\n",
      " 20\n",
      "[0.7496159754224271, 0.7956989247311828, 0.8079877112135176, 0.7987711213517665, 0.8125960061443932, 0.8064516129032258, 0.8310291858678955, 0.7649769585253456, 0.8064516129032258, 0.7741935483870968, 0.8294930875576036, 0.82642089093702, 0.8218125960061444, 0.8218125960061444, 0.8172043010752689, 0.8125960061443932, 0.8202764976958525, 0.8079877112135176, 0.8341013824884793, 0.7557603686635944]\n"
     ]
    }
   ],
   "source": [
    "def plt_resize_text(labelsize, titlesize):\n",
    "    ax = plt.subplot()\n",
    "    for ticklabel in (ax.get_xticklabels()):\n",
    "        ticklabel.set_fontsize(labelsize)\n",
    "    for ticklabel in (ax.get_yticklabels()):\n",
    "        ticklabel.set_fontsize(labelsize)\n",
    "    ax.xaxis.get_label().set_fontsize(labelsize)\n",
    "    ax.yaxis.get_label().set_fontsize(labelsize)\n",
    "    ax.title.set_fontsize(titlesize)\n",
    "\n",
    "# Show comparison of different models as bar diagram\n",
    "plt.close(\"all\")\n",
    "plt.xticks(train_dataset_sizes)\n",
    "plt.bar(train_dataset_sizes, classification_rates)\n",
    "plt.title(\"Comparison of classification rates\")\n",
    "plt.xlabel(\"Nr of training images per class\")\n",
    "plt.ylabel(\"Correct classifcation rate\")\n",
    "#plt_resize_text(8,15)\n",
    "plt.show()\n",
    "\n",
    "min_rate = min(classification_rates)\n",
    "max_rate = max(classification_rates)\n",
    "\n",
    "print(\"Minimum rate:\", min_rate)\n",
    "print(\"Maximum rate:\", max_rate)\n",
    "print(\"Range in percent:\", (max_rate-min_rate)*100.0)\n",
    "\n",
    "print(len(train_dataset_sizes))\n",
    "print(train_dataset_sizes)\n",
    "print(\"\\n\",len(classification_rates))\n",
    "print(classification_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
