{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">Multi-Layer Perceptron (MLP) example in Keras <br> for house sales price prediction<br>using ONLY categorial features\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    " by Prof. Dr.-Ing. JÃ¼rgen Brauer, http://www.juergenbrauer.org\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Retrieve-categorial-feature-columns-from-data\" data-toc-modified-id=\"Retrieve-categorial-feature-columns-from-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Retrieve categorial feature columns from data</a></span></li><li><span><a href=\"#Show-for-a-categorial-column-possible-values\" data-toc-modified-id=\"Show-for-a-categorial-column-possible-values-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Show for a categorial column possible values</a></span></li><li><span><a href=\"#One-hot-encoding-for-categorial-columns\" data-toc-modified-id=\"One-hot-encoding-for-categorial-columns-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>One-hot encoding for categorial columns</a></span></li><li><span><a href=\"#Analyse-datatype-of-one-hot-encoded-columns\" data-toc-modified-id=\"Analyse-datatype-of-one-hot-encoded-columns-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Analyse datatype of one-hot encoded columns</a></span></li><li><span><a href=\"#Encoding-all-categorial-feature-columns-by-one-hot-encoding\" data-toc-modified-id=\"Encoding-all-categorial-feature-columns-by-one-hot-encoding-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Encoding all categorial feature columns by one-hot encoding</a></span></li><li><span><a href=\"#Scaling-the-data-and-preparing-training-matrices\" data-toc-modified-id=\"Scaling-the-data-and-preparing-training-matrices-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Scaling the data and preparing training matrices</a></span></li><li><span><a href=\"#Building-the-MLP-model-and-training-it\" data-toc-modified-id=\"Building-the-MLP-model-and-training-it-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Building the MLP model and training it</a></span></li><li><span><a href=\"#Testing-the-trained-MLP\" data-toc-modified-id=\"Testing-the-trained-MLP-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Testing the trained MLP</a></span></li><li><span><a href=\"#Predicting-house-prices-for-the-Kaggle-competition\" data-toc-modified-id=\"Predicting-house-prices-for-the-Kaggle-competition-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Predicting house prices for the Kaggle competition</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve categorial feature columns from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"kaggle_dataset_house_prices/train.csv\")\n",
    "test_data  = pd.read_csv(\"kaggle_dataset_house_prices/test.csv\")\n",
    "\n",
    "# save the house Ids, since we need them later\n",
    "# for our Kaggle submission\n",
    "test_house_ids = test_data.values[:,0] # get the IDs from the original Pandas DataFrame\n",
    "\n",
    "train_data.fillna(0, inplace=True)\n",
    "test_data.fillna(0, inplace=True)\n",
    "\n",
    "gt_saleprice = train_data[\"SalePrice\"]\n",
    "train_data = train_data.select_dtypes(exclude=['number'])\n",
    "test_data = test_data.select_dtypes(exclude=['number'])\n",
    "\n",
    "print(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show for a categorial column possible values\n",
    "\n",
    "It is interesting to see which values a categorial variable can have and how often these individual categorial values occur. Let's choose a categorial variable, e.g. `GarageQual` and get all the values that can appear and how often:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( train_data['GarageQual'].value_counts() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the 6 possible values of the garage quality mentioned in `data_description.txt`:\n",
    "\n",
    "    Ex\tExcellent\n",
    "    Gd\tGood\n",
    "    TA\tTypical/Average\n",
    "    Fa\tFair\n",
    "    Po\tPoor\n",
    "    NA\tNo Garage (which we mapped using fillna() to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = train_data['GarageQual'].astype('category').cat.categories.tolist()\n",
    "print(labels)\n",
    "print(\"labels has type\",type(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to plot a nice pie chart for showing visually how often a certain value of category appears in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = train_data['GarageQual'].astype('category').cat.categories.tolist()\n",
    "counts = train_data['GarageQual'].value_counts()\n",
    "sizes = [counts[var_cat] for var_cat in labels]\n",
    "\n",
    "plt.figure()\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding for categorial columns\n",
    "\n",
    "A simple approach is to use a one-hot encoding to encode categorial features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "garagequal_only = train_data[\"GarageQual\"]\n",
    "print(garagequal_only)\n",
    "garagequal_only_hot = pd.get_dummies(garagequal_only,\n",
    "                                     columns=['GarageQual'],\n",
    "                                     prefix = 'GarageQuality')\n",
    "print(garagequal_only_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyse datatype of one-hot encoded columns\n",
    "\n",
    "For one `GarageQual` categorial feature column which had data type \"object\" and where the categorial feature could have six different values [0, 'Ex', 'Fa', 'Gd', 'Po', 'TA'], we made six one-hot encoded feature columns.\n",
    "\n",
    "In column `Gd` (Good) we will see a `1` for a house, if the garage quality is classified as \"good\" and otherwise we will see a `0`.\n",
    "\n",
    "But what is the data type of this new feature columns? Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"garagequal_only_hot is a \", type(garagequal_only_hot))\n",
    "print(garagequal_only_hot.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the data type is an unsigned integer. This makes sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding all categorial feature columns by one-hot encoding\n",
    "\n",
    "Now there are ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(train_data.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... categorial feature columns in our original Pandas Dataframe `train_data`. Fortunately, we can replace all feature columns in one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_hot = pd.get_dummies(train_data)\n",
    "print(train_data_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how powerful Pandas is! One command does all the work for us. However, we can see that e.g. for the feature `MSZoning` which can have the values\n",
    "\n",
    "    A   Agriculture\n",
    "    C   Commercial\n",
    "    FV  Floating Village Residential\n",
    "    I   Industrial\n",
    "    RH  Residential High Density\n",
    "    RL  Residential Low Density\n",
    "    RP  Residential Low Density Park \n",
    "    RM  Residential Medium Density\n",
    "\n",
    "according to `data_description.txt` only 5 columns were generated, although there are in principal 8 possible values `(A,C,FV,I,RH,RL,RP,RM)` for this categorial feature:\n",
    "\n",
    "    MSZoning_C (all) \tMSZoning_FV \tMSZoning_RH \tMSZoning_RL \tMSZoning_RM\n",
    "   \n",
    "What's the reason? Well, Pandas can only see the values that are really there in the table! Not more! It does not know, that these feature can in principle also have the value \"A\", if there is not a single row in the data frame where this value appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_mszoning = train_data['MSZoning'].astype('category').cat.categories.tolist()\n",
    "print(labels_mszoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we have to make sure, that the training data columns and the test data columns are encoded in the same way! Let's check this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_hot = pd.get_dummies(train_data)\n",
    "test_data_hot = pd.get_dummies(test_data)\n",
    "print(\"Shape of train_data_hot is\", train_data_hot.shape)\n",
    "print(\"Shape of test_data_hot is\", test_data_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ups! We can see that there are in the test table only 256 compared to 268 columns, i.e., there are fewer values of some categorial features and for this, Pandas uses another one-hot encoding for the test data features as for the training data features! This is bad! :( \n",
    "\n",
    "Why is this a problem? We cannot use training vectors of size 268 and later give the network 256 dimensional input vectors for inference, where the individual entries of this 256D input vectors also have other meanings compared to the individual entries of the 268D vectors used during training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we do to solve this problem? ... I personally just went to get a coffee ... Then I had the idea! We want `get_dummies` to see ALL possible values that appear in my training and in my test data. So let's build a new dataset, where we stack...\n",
    "\n",
    "    train.csv (1460 rows)\n",
    "    test.csv (1459 rows)\n",
    "    \n",
    "... both data sets, then call `get_dummies` to do the 1-hot encoding on the fused data frame and then split the 1-hot encoded data frame again into two parts (training and testing). Coffee is the driving force behind innovation! ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Shape of train_data is \", train_data.shape)\n",
    "print(\"Shape of test_data is \", test_data.shape)\n",
    "print(\"Column names of train_data are:\\n\", train_data.columns.values)\n",
    "print(\"Column names of test_data are:\\n\", test_data.columns.values)\n",
    "frames = [train_data, test_data]\n",
    "fused_df = pd.concat(frames)\n",
    "#print(fused_df)\n",
    "print(\"Shape of fused_df is\", fused_df.shape)\n",
    "\n",
    "# now do the one-hot encoding\n",
    "fused_df_hot_encoded = pd.get_dummies(fused_df)\n",
    "print(\"Shape of fused_df_hot_encoded is\", fused_df_hot_encoded.shape)\n",
    "\n",
    "# now split the data frame into two data frames again\n",
    "# with 1460 and 1459 rows\n",
    "train_data_hot_encoded = fused_df_hot_encoded[0:1460]\n",
    "test_data_hot_encoded  = fused_df_hot_encoded[1460:]\n",
    "print(\"Shape of train_data_hot_encoded is \", train_data_hot_encoded.shape)\n",
    "print(\"Shape of test_data_hot_encoded is \", test_data_hot_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem solved!\n",
    "\n",
    "Our categorial training data is now one-hot encoded in `train_data_hot_encoded`<br>\n",
    "Our categorial test data is now one-hot encoded in `test_data_hot_encoded`\n",
    "\n",
    "Both one-hot encoded data matrices have 275 feature columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the data and preparing training matrices\n",
    "\n",
    "When we just used numerical features for predicting house sale prices, we rescaled all the numerical features to range [0,1] in order to make it easier for the MLP to learn appropriate weights.\n",
    "\n",
    "Here - where we use just categorial one-hot encoded features - a scaling of the input data is not needed! All values are 0 or 1. However, we need to prepare NumPy matrices and scale the output (sale price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. define how NumPy shall print matrices\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True) # do not use scientific \"e\"-notation\n",
    "\n",
    "# 2. convert Pandas DataFrame to NumPy matrices\n",
    "#    since Keras will expect NumPy matrices\n",
    "cat_train_input_matrix = train_data_hot_encoded.values\n",
    "train_output_matrix    = gt_saleprice.values\n",
    "train_output_matrix    = train_output_matrix.reshape(-1,1)\n",
    "cat_test_input_matrix  = test_data_hot_encoded.values\n",
    "print(\"Type of cat_train_input_matrix is\", type(cat_train_input_matrix))\n",
    "print(\"Shape of cat_train_input_matrix is\", cat_train_input_matrix.shape)\n",
    "print(\"Shape of train_output_matrix is\", train_output_matrix.shape)\n",
    "print(\"Shape of cat_test_input_matrix is\", cat_test_input_matrix.shape)\n",
    "print(\"train_data_hot_encoded:\\n\", train_data_hot_encoded)\n",
    "print(\"cat_train_input_matrix:\\n\", cat_train_input_matrix)\n",
    "\n",
    "# 3. create a MinMaxScaler for the train_output_matrix,\n",
    "#    which is essentially a column with the final SalePrice\n",
    "scaler_saleprice = MinMaxScaler(feature_range=(0, 1))\n",
    "normalized_train_output_matrix = scaler_saleprice.fit_transform(train_output_matrix)\n",
    "print(\"\\ntrain_output_matrix:\\n\", train_output_matrix)\n",
    "print(\"\\nnormalized_train_output_matrix:\\n\", normalized_train_output_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the MLP model and training it\n",
    "\n",
    "Now we can use the training data to train a MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers.core import Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(160, activation=\"linear\"))\n",
    "model.add(Dense(80, activation=\"linear\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X = cat_train_input_matrix\n",
    "Y = normalized_train_output_matrix\n",
    "print(\"Input X has shape\", X.shape)\n",
    "print(\"Desired output Y has shape\", Y.shape)\n",
    "print(\"Y:\\n\", Y)\n",
    "model.fit(X,Y, validation_split=0.10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing the trained MLP\n",
    "\n",
    "Normally we test a model on a separate test data set. However, in this case, there is no test dataset, since the test data only contains the input features, but not the final sale prices of the houses.\n",
    "\n",
    "For this, let us see how good the trained model can predict the sale prices of the houses from the training dataset ONLY using the categorial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_train_houses = model.predict(cat_train_input_matrix)\n",
    "print(\"preds_train_houses:\\n\", preds_train_houses)\n",
    "preds_train_houses_dollar = scaler_saleprice.inverse_transform(preds_train_houses)\n",
    "print(\"preds_train_houses_dollar:\\n\", preds_train_houses_dollar)\n",
    "print(\"Shape of preds_train_houses is\", preds_train_houses.shape)\n",
    "print(\"Shape of preds_train_houses_dollar is\", preds_train_houses_dollar.shape)\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.plot(train_output_matrix, preds_train_houses_dollar, 'ro')\n",
    "plt.xlabel('Real house price', fontsize = 10)\n",
    "plt.ylabel('Predicted house price', fontsize = 10)\n",
    "plt.grid(True)\n",
    "plt.xlim(0,900000)\n",
    "plt.ylim(0,900000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compute the average prediction error made in Dollars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"preds_train_houses_dollar:\\n\", preds_train_houses_dollar)\n",
    "print(\"train_output_matrix:\\n\", train_output_matrix)\n",
    "absdiff = np.abs(preds_train_houses_dollar - train_output_matrix)\n",
    "print(absdiff)\n",
    "average_error_in_dollar = np.mean(absdiff)\n",
    "print(\"The final trained model made an average error of $%.2f\" % average_error_in_dollar,\n",
    "      \"when predicting the house prices on the training data when ONLY using\"\n",
    "      \"categorial features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices for the Kaggle competition\n",
    "\n",
    "Now we will use the trained MLP to predict the prices of the houses for which only the features are given, but not the sale price!\n",
    "\n",
    "This file can be uploaded at Kaggle to take part at the Kaggle competition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREDICT house prices for all the test houses!\n",
    "preds_test_houses = model.predict(cat_test_input_matrix)\n",
    "preds_test_houses_dollar = scaler_saleprice.inverse_transform(preds_test_houses)\n",
    "\n",
    "\n",
    "# generate a Pandas dataframe\n",
    "# from the NumPy prediction_matrix\n",
    "preds_test_houses_dollar = preds_test_houses_dollar.reshape(-1)\n",
    "print(\"test_house_ids has shape\", test_house_ids.shape)\n",
    "print(\"preds_test_houses_dollar has shape\", preds_test_houses_dollar.shape)\n",
    "predition_dataframe = pd.DataFrame({'Id'       :test_house_ids,\n",
    "                                    'SalePrice':preds_test_houses_dollar}\n",
    "                                  )\n",
    "\n",
    "# convert column \"Id\" to int64 dtype\n",
    "predition_dataframe = predition_dataframe.astype({\"Id\": int})\n",
    "print(predition_dataframe)\n",
    "\n",
    "# now save the Pandas dataframe to a .csv file\n",
    "PREDICTION_FILENAME = \"my_predicted_house_prices.csv\"\n",
    "predition_dataframe.to_csv(PREDICTION_FILENAME, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
